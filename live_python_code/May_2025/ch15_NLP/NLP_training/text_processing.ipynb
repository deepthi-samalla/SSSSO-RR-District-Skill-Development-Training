{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7233eea6-90d1-41d0-a849-a125d0c3582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b77ef76b-3957-40e3-8ef4-052784c8b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello!!! This is an example: NLP @2024 with #Python. Let's clean it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75160f79-9d4e-467f-823d-4b5be36e3f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello!!! this is an example: nlp @2024 with #python. let's clean it.\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Lowercase\n",
    "text_lower = text.lower()\n",
    "print(text_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a71d51f-9cd9-4d71-b439-10945cc844d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello This is an example NLP 2024 with Python Lets clean it\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Remove punctuation\n",
    "text_no_punct = re.sub(r'[^\\w\\s]', '', text)\n",
    "print(text_no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa75d5d4-c958-4120-bf0d-334bf9926f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello This is an example NLP  with Python Lets clean it\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Remove numbers\n",
    "text_no_numbers = re.sub(r'\\d+', '', text_no_punct)\n",
    "print(text_no_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d2d2866-b526-41ef-9ba6-2b78ccb3b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello This is an example NLP with Python Lets clean it\n"
     ]
    }
   ],
   "source": [
    "# Example 4: Remove extra whitespace\n",
    "text_clean = \" \".join(text_no_numbers.split())\n",
    "print(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cac62124-f025-49dd-aae3-08977f306f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'This', 'example', 'NLP', 'Python', 'Lets', 'clean']\n"
     ]
    }
   ],
   "source": [
    "# Example 5: Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#print(stop_words)\n",
    "filtered_words = [w for w in text_clean.split() if w not in stop_words]\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a165d3d2-2d8a-424e-ab15-7538e31a3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "food is good --> +Ve\n",
    "food is not good --> -ve\n",
    "food is not bad --> +ve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "505fa5b6-9925-43b9-9b82-1510450f1d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!!! This is an example: NLP 2024 with Python. Let's clean it.\n"
     ]
    }
   ],
   "source": [
    "# Example 6: Remove special characters (like hashtags)\n",
    "text_no_special = re.sub(r'[#@]', '', text)\n",
    "print(text_no_special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b687656a-8eb5-4ad6-94bc-803db606202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'thi', 'exampl', 'nlp', 'python', 'let', 'clean']\n"
     ]
    }
   ],
   "source": [
    "# Example 7: Stemming\n",
    "st = \"stepping\"\n",
    "ps = PorterStemmer()\n",
    "stemmed = [ps.stem(w) for w in filtered_words]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7253410-7af8-4037-9d99-95bd0bc80293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'This', 'example', 'NLP', 'Python', 'Lets', 'clean']\n"
     ]
    }
   ],
   "source": [
    "# Example 8: Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bc9c75f-1449-485b-8abf-90f190bfb1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!!! His is an example: NLP @2024 with #Python. Met's clean it.\n"
     ]
    }
   ],
   "source": [
    "# Example 9: Spell correction (using textblob)\n",
    "#!pip install textblob\n",
    "from textblob import TextBlob\n",
    "corrected = str(TextBlob(text).correct())\n",
    "print(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c40df3-4969-4a85-9d67-3c235531b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello!!! This is an example: NLP @2024 with #Python. Let's clean it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "007f6622-ae61-444c-986a-78e25db7c0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "# Example 10: Remove HTML tags (if present)\n",
    "html_text = \"Hello world!\"\n",
    "clean_html = re.sub(r'<.*?>', '', html_text)\n",
    "print(clean_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00501e5d-70f1-4347-b0dd-b123bba0393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', '!', '!', 'This', 'is', 'an', 'example', ':', 'NLP', '@2024', 'with', '#', 'Python', '.', 'Let', \"'s\", 'clean', 'it', '.']\n"
     ]
    }
   ],
   "source": [
    "# Example 4: Using SpaCy tokenizer\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4741172e-d84b-4c42-9c11-adbbcee925fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
